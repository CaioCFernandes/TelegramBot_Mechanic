import os
import google.generativeai as genai
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import filters, ApplicationBuilder, ContextTypes, MessageHandler

# Carrega vari√°veis
load_dotenv(".env")

# Configura a IA (Google Gemini)
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Configura√ß√£o do Modelo
generation_config = {
    "temperature": 0.4, # Baixa temperatura para ele ser mais "t√©cnico" e menos "criativo/alucinado"
}

# Escolhendo o modelo que vimos na sua lista que funciona bem
model = genai.GenerativeModel(
    model_name="models/gemini-2.5-flash", 
    generation_config=generation_config
)

async def consultor_automotivo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text
    
    # Feedback visual ("escrevendo...")
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action='typing')

    try:
        # --- O C√âREBRO: PROMPT DE SISTEMA ---
        # Aqui definimos que ele √© um especialista em carros
        prompt_sistema = (
            "Voc√™ √© um Consultor Automotivo S√™nior e Especialista em Mercado Brasileiro. "
            "Sua fun√ß√£o √© ajudar o usu√°rio a escolher ou conhecer carros. "
            "Seja direto, educado e use formata√ß√£o bonita (Markdown/Emojis). "
            
            "MODO 1: SE O USU√ÅRIO PERGUNTAR DE UM CARRO ESPEC√çFICO (Ex: 'Civic 2010')"
            "Retorne uma ficha t√©cnica RESUMIDA contendo obrigatoriamente:"
            "- üöó Nome Completo e Motoriza√ß√£o prov√°vel"
            "- ‚öôÔ∏è C√¢mbio (Autom√°tico/Manual)"
            "- ‚õΩ Consumo M√©dio (Cidade/Estrada)"
            "- üõ†Ô∏è Manuten√ß√£o (Barata/M√©dia/Cara)"
            "- ‚úÖ Pontos Positivos"
            "- ‚ö†Ô∏è Pontos de Aten√ß√£o (Defeitos cr√¥nicos conhecidos)"
            "- üí∞ Pre√ßo M√©dio de Mercado (Estimativa Brasil)"
            
            "MODO 2: SE O USU√ÅRIO PEDIR RECOMENDA√á√ÉO (Ex: 'Carro pra fam√≠lia at√© 50k')"
            "Analise o or√ßamento e o uso. Sugira 3 op√ß√µes de carros bons de mercado."
            "Para cada op√ß√£o, diga o modelo, ano aproximado e por que ele √© bom para aquele uso."
            
            "MODO 3: DADOS INCOMPLETOS"
            "Se o usu√°rio falar apenas 'Civic', pergunte educadamente: 'Qual o ano e vers√£o aproximada? Isso muda o motor e o pre√ßo.' "
            
            "IMPORTANTE: Baseie-se no mercado brasileiro (carros nacionais ou importados vendidos no Brasil)."
        )

        # Montamos a conversa para enviar a IA
        # O Gemini aceita o contexto dentro do prompt ou como hist√≥rico.
        # Vamos mandar tudo junto para garantir a instru√ß√£o.
        full_prompt = f"{prompt_sistema}\n\n--- MENSAGEM DO USU√ÅRIO: {user_msg} ---"

        response = model.generate_content(full_prompt)
        
        # TENTATIVA SEGURA DE ENVIO
        try:
            # Tenta enviar com formata√ß√£o bonita (Markdown)
            await update.message.reply_text(response.text, parse_mode='Markdown')
        except Exception as e_telegram:
            print(f"Erro de formata√ß√£o Markdown ({e_telegram}). Enviando texto puro...")
            # Se falhar (por causa de um _ ou * solto), envia o texto puro
            await update.message.reply_text(response.text)

    except Exception as e:
        print(f"Erro geral: {e}")
        await update.message.reply_text("Desculpe, estou com uma falha no motor agora (Erro t√©cnico).")

# Configura√ß√£o do Bot
application = ApplicationBuilder().token(str(os.getenv("token"))).build()

# Handler √∫nico: O bot l√™ tudo e a IA decide o que fazer
handler = MessageHandler(filters.TEXT & (~filters.COMMAND), callback=consultor_automotivo)
application.add_handler(handler)

print("Consultor Automotivo IA iniciado! üöó")
application.run_polling()